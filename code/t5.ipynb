{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, Dataset,concatenate_datasets\n",
    "import pandas as pd\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "from openprompt.data_utils import InputExample\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts import ManualTemplate\n",
    "from openprompt.plms import T5TokenizerWrapper\n",
    "from openprompt import PromptDataLoader\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "import torch\n",
    "from openprompt import PromptForClassification\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "import os\n",
    "\n",
    "def t5_model(model_full_name,n_samples,epochs):\n",
    "\n",
    "    dataset_path=r\"data/Train.csv\"\n",
    "    model_root_name=\"t5\"\n",
    "    # model_full_name=\"google/mt5-base\"\n",
    "    # n_samples = 8\n",
    "\n",
    "    df=pd.read_csv(dataset_path)\n",
    "\n",
    "\n",
    "    df_neutral = df[df['Label'] == 0].sample(n=n_samples, random_state=1)\n",
    "    df_positive = df[df['Label'] == 1].sample(n=n_samples, random_state=1)\n",
    "    df_negative = df[df['Label'] == 2].sample(n=n_samples, random_state=1)\n",
    "\n",
    "\n",
    "    df_sampled = pd.concat([df_neutral, df_positive, df_negative], ignore_index=True)\n",
    "\n",
    "\n",
    "    dataset = Dataset.from_pandas(df_sampled)\n",
    "    raw_dataset=dataset.train_test_split(test_size=0.5)\n",
    "\n",
    "    dataset = {}\n",
    "    for split in ['train', 'test']:\n",
    "        dataset[split] = []\n",
    "        for idx,data in enumerate(raw_dataset[split]):\n",
    "            input_example = InputExample(text_a = data['Data'], label=int(data['Label']), guid=idx)\n",
    "            dataset[split].append(input_example)\n",
    "    plm, tokenizer, model_config, WrapperClass = load_plm(model_root_name,model_full_name )\n",
    "\n",
    "    # template_text = '{\"placeholder\":\"text_a\"}. এটা হল {\"mask\"}.'\n",
    "\n",
    "    template_text = '{\"placeholder\":\"text_a\"}. sentiment in Bangla: {\"mask\"}.'\n",
    "    # template_text = '[CLS] {\"placeholder\":\"text_a\"}. Sentiment: {\"mask\"}. [SEP]'\n",
    "    mytemplate = ManualTemplate(tokenizer=tokenizer, text=template_text)\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['<mask>']})\n",
    "    wrapped_t5tokenizer= T5TokenizerWrapper(max_seq_length=128, decoder_max_length=3, tokenizer=tokenizer,truncate_method=\"head\")\n",
    "\n",
    "\n",
    "    train_dataloader = PromptDataLoader(dataset=dataset[\"train\"], template=mytemplate, tokenizer=tokenizer,\n",
    "        tokenizer_wrapper_class=WrapperClass, max_seq_length=256, decoder_max_length=3,\n",
    "        batch_size=4,shuffle=True, teacher_forcing=False, predict_eos_token=False,\n",
    "        truncate_method=\"head\")\n",
    "\n",
    "\n",
    "\n",
    "    # for example the verbalizer contains multiple label words in each class\n",
    "    myverbalizer = ManualVerbalizer(tokenizer, num_classes=3,\n",
    "                            label_words=[[\"Neutral\"], [\"Positive\"], [\"Negative\"]])\n",
    "\n",
    "\n",
    "\n",
    "    use_cuda = True\n",
    "    prompt_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n",
    "    if use_cuda:\n",
    "        prompt_model=  prompt_model.cuda()\n",
    "\n",
    "    # Now the training is standard\n",
    "\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    # it's always good practice to set no decay to biase and LayerNorm parameters\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=1e-4)\n",
    "    for epoch in range(epochs):\n",
    "        tot_loss = 0\n",
    "        for step, inputs in enumerate(train_dataloader):\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            logits = prompt_model(inputs)\n",
    "            labels = inputs['label']\n",
    "            loss = loss_func(logits, labels)\n",
    "            loss.backward()\n",
    "            tot_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if step %100 ==1:\n",
    "                print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
    "\n",
    "    validation_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer,\n",
    "        tokenizer_wrapper_class=WrapperClass, max_seq_length=256, decoder_max_length=3,\n",
    "        batch_size=4,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "        truncate_method=\"head\")\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "    for step, inputs in enumerate(validation_dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        labels = inputs['label']\n",
    "        alllabels.extend(labels.cpu().tolist())\n",
    "        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "\n",
    "    acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "    file_path = 'result.txt'\n",
    "    string_to_write = f\"********\\nNumber of samples per class: {n_samples}\\nEpochs: {epochs}\\nmodel_root_name: {model_root_name}\\nmodel_full_name: {model_full_name}\\ntemplate_text: {template_text}\\nAccuracy: {acc}\\n********\\n\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'a') as file:\n",
    "            file.write(string_to_write)\n",
    "    else:\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(string_to_write)\n",
    "    print(f\"acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model(\"google/mt5-base\",4,20)\n",
    "t5_model(\"google/mt5-base\",8,20)\n",
    "t5_model(\"google/mt5-base\",16,20)\n",
    "t5_model(\"google/mt5-base\",32,20)\n",
    "\n",
    "t5_model(\"csebuetnlp/banglat5\",4,20)\n",
    "t5_model(\"csebuetnlp/banglat5\",8,20)\n",
    "t5_model(\"csebuetnlp/banglat5\",16,20)\n",
    "t5_model(\"csebuetnlp/banglat5\",32,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openprompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
